# ğŸ§‘â€ğŸ’» Parcial 2 â€“ Inteligencia Artificial Aplicada

Este repositorio contiene la entrega del **Parcial 2** de la materia *HE2 â€“ Inteligencia Artificial Aplicada*.  
El objetivo es predecir si una persona gana mÃ¡s de **50.000 USD** anuales usando el dataset **Adult Census Income** del repositorio UCI.

## ğŸ“‚ Contenido
- ğŸ““ `Parcial_2.ipynb`: Notebook en Google Colab con todo el desarrollo (EDA, baseline, MLP en PyTorch).  
- ğŸ“„ `Reporte_Parcial 2.pdf`: Reporte escrito con las respuestas al parcial.  
- ğŸ“Š `adult_train_profile.html`: Reporte exploratorio (EDA) del conjunto de **entrenamiento**.  
- ğŸ“Š `adult_val_profile.html`: Reporte exploratorio (EDA) del conjunto de **validaciÃ³n**.  
- ğŸ“Š `adult_test_profile.html`: Reporte exploratorio (EDA) del conjunto de **prueba**.  
- ğŸ“‘ `resumen_experimentos.csv`: Resumen tabular de los resultados de todos los experimentos (sin y con regularizaciÃ³n).  

## ğŸš€ Flujo de trabajo
1. **Procesamiento de datos**  
   - Limpieza de etiquetas y valores nulos.  
   - EliminaciÃ³n de variables redundantes (`education`) y poco informativas (`fnlwgt`).  
   - ImputaciÃ³n de categorÃ­as faltantes con `"Unknown"`.  
   - Escalado con `StandardScaler` en numÃ©ricas y `OneHotEncoding` en categÃ³ricas.  
   - Split 50/50 del set de prueba â†’ validaciÃ³n y test.  

2. **Modelos implementados**  
   - ğŸ”¹ **Baseline**: RegresiÃ³n LogÃ­stica.  
   - ğŸ”¹ **Redes Neuronales (MLP)** en PyTorch, con experimentos **sin regularizaciÃ³n** y con **Dropout + Weight Decay + EarlyStopping**.  

3. **Experimentos**  
   - â‰¥5 configuraciones de hiperparÃ¡metros **sin regularizaciÃ³n**.  
   - â‰¥5 configuraciones **con regularizaciÃ³n**.  
   - Registro de mÃ©tricas y pÃ©rdidas por Ã©poca.  

4. **EvaluaciÃ³n**  
   - MÃ©tricas: **PrecisiÃ³n, Recall, F1 y AUC** (se priorizan sobre Accuracy por el desbalance de clases).  
   - ComparaciÃ³n: Baseline vs MLP (sin regularizaciÃ³n vs con regularizaciÃ³n).  

## ğŸ“Š Resultados principales
- **Mejor sin regularizaciÃ³n**: `EXP5_capacidad_mÃ­nima_batch_grande_sin_reg`  
  - F1 (val) = 0.6537 | F1 (test) = 0.6828 | AUC (test) = 0.9126.  
  - Ajuste razonable sin seÃ±ales fuertes de sobreajuste.  

- **Mejor con regularizaciÃ³n**: `EXP5_con_reg_R5(p=0.5, wd=1e-2)`  
  - F1 (val) = 0.6612 | F1 (test) = 0.6915 | AUC (test) = 0.9162.  
  - RegularizaciÃ³n mejorÃ³ la capacidad de generalizaciÃ³n.  

- **ComparaciÃ³n con baseline (RegresiÃ³n LogÃ­stica)**:  
  - LogÃ­stica logra mayor **recall (~0.84)** pero baja precisiÃ³n (~0.57).  
  - El MLP regulado logra **mayor precisiÃ³n (~0.74)** y mejor F1/AUC, mostrando un **balance mÃ¡s sÃ³lido** en un dataset desbalanceado.  

âœ… **ConclusiÃ³n:** El mejor modelo global fue el **MLP con regularizaciÃ³n (EXP5 R5)**, ya que superÃ³ a los demÃ¡s en F1 y AUC, confirmando que la regularizaciÃ³n ayudÃ³ a mejorar el equilibrio entre precisiÃ³n y recall.  

## ğŸ› ï¸ Requisitos
- Python 3.9+  
- PyTorch  
- Scikit-learn  
- Pandas / Numpy / Matplotlib  

## ğŸ™Œ Autores
Entrega desarrollada por **Gabriela Zamora, Gilberto Galeana y SofÃ­a Anzola OrtegÃ³n**.  

