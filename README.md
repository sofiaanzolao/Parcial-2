# Parcial-2
# ğŸ§‘â€ğŸ’» Parcial 2 â€“ Inteligencia Artificial Aplicada

Este repositorio contiene la entrega del **Parcial 2** de la materia *HE2 â€“ Inteligencia Artificial Aplicada*.  
El objetivo del proyecto es predecir si una persona gana mÃ¡s de **$50.000 USD** anuales usando el dataset **Adult Census Income** del repositorio UCI.

## ğŸ“‚ Contenido
- ğŸ““ `Parcial_2.ipynb`: Notebook en Google Colab con todo el desarrollo (EDA, baseline, MLP en PyTorch).
- ğŸ“„ `Reporte_Parcial_2.pdf`: Reporte escrito con respuestas a las preguntas solicitadas.
- ğŸ“Š `adult_train_profile.html`: Reporte exploratorio (EDA) del conjunto de **entrenamiento**.
- ğŸ“Š `adult_val_profile.html`: Reporte exploratorio (EDA) del conjunto de **validaciÃ³n**.
- ğŸ“Š `adult_test_profile.html`: Reporte exploratorio (EDA) del conjunto de **prueba**.

## ğŸš€ Flujo de trabajo
1. **RecolecciÃ³n y procesamiento de datos**  
   - Limpieza y normalizaciÃ³n  
   - OneHotEncoding + StandardScaler  
   - Split 50/50 del test â†’ validaciÃ³n y prueba  

2. **Modelos**  
   - ğŸ”¹ Baseline: RegresiÃ³n LogÃ­stica  
   - ğŸ”¹ MLP en PyTorch (con y sin regularizaciÃ³n)  

3. **Experimentos**  
   - â‰¥5 configuraciones de hiperparÃ¡metros sin regularizaciÃ³n  
   - â‰¥5 configuraciones con Dropout + EarlyStopping  

4. **EvaluaciÃ³n**  
   - MÃ©tricas: Accuracy, PrecisiÃ³n, Recall, F1 y AUC  
   - ComparaciÃ³n entre regresiÃ³n logÃ­stica y MLP  

## ğŸ“Š Resultados esperados
- El baseline (logÃ­stica) ofrece un punto de referencia.  
- El MLP sin regularizaciÃ³n muestra riesgo de **overfitting**.  
- El MLP con Dropout y EarlyStopping mejora la capacidad de generalizaciÃ³n.  

## ğŸ› ï¸ Requisitos
- Python 3.9+  
- PyTorch  
- Scikit-learn  
- Pandas / Numpy / Matplotlib  

## ğŸ™Œ Autor
Entrega desarrollada por **Gabriela Zamora, Gilberto Galeana y SofÃ­a Anzola**.
